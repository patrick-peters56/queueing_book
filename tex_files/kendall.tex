\section{Kendall's Notation}
\label{sec:kendalls-notation}



\opt{solutionfiles}{
\subsection*{Theory and Exercises}
\Opensolutionfile{hint}
\Opensolutionfile{ans}
}


As became apparent in~\cref{sec:constr-discr-time,sec:constr-gg1-queu}, the construction of any single-station queueing process involves three main elements: the distribution of the inter-arrival times between consecutive jobs, the distribution of the service times of the individual jobs, and the number of servers present to process jobs.
In this characterization, it is implicit that the inter-arrival times form a set of i.i.d.
(independent and identically distributed) random variables, the service times are also i.i.d., and finally, the inter-arrival times and service times are mutually independent.

To characterize the type of queueing process it is common to use 
\recall{Kendall's abbreviation} $A/B/c/K$, where $A$ is the distribution of the
inter-arrival times, $B$ the distribution of the service times, $c$ the
number of servers, and $K$ the system size, i.e., the total number of customers that can be simultaneously present, whether in queue or in service.\footnote{The meaning of $K$ differs among authors. Sometimes it stands for
 the capacity of the queue, not the entire system. In this book $K$ corresponds to the system's size.}
In this notation it is assumed that jobs are served in
first-in-first-out (FIFO) order; FIFO scheduling is also often called
first-come-first-served (FCFS). 

When at an arrival a number of jobs arrive simultaneously (like a bus at a restaurant), we say that a batch arrives.
Likewise, the server can work in batches, for instance, when an oven processes multiple jobs at the same time.
We write $A^X/B^Y/c$ to denote that $X$ is the distribution of the arrival batch size and $Y$ is the distribution of the service batch sizes.
When $X\equiv Y \equiv 1$, i.e., single batch arrivals and single batch services, we suppress the $X$ and $Y$ in the queueing formula.


Two inter-arrival and service distributions are the most important in queueing theory: the exponential distribution denoted with the shorthand $M$, as it is memoryless, and a general distribution (with the implicit assumption that its first moment is finite) denoted with $G$. We write $D$ for a deterministic (constant) random variable. 

Familiarize yourself with this notation as it is used continuously in the rest of the book. Here are some exercises to illustrate the notation.

\begin{extra}
 What is the meaning of $M/M/1$?
\begin{solution}
$M/M/1$: The distribution of the inter-arrival times is
 memoryless, hence exponential, the service times are also
 memoryless, and there is 1 server. As $K$ is unspecified, the system can contain any number of jobs.
\end{solution}
\end{extra}

\begin{extra}
 By how many parameters is the $M/M/1$ queue characterized?
\begin{solution}
 The inter-arrival times are exponentially distributed with rate $\lambda$; the service times are also exponential, but with parameter $\mu$. Thus, if we know $\lambda$ and $\mu$, we have fully characterized the parameters of both distributions. Since the number of servers is 1, only $\lambda$ and $\mu$ remain.
\end{solution}
\end{extra}

\begin{extra}
What is the $D/D/1$ queue? 
\begin{solution}
$D/D/1$: A queueing process with deterministic inter-arrival times, deterministic service times and 1 server.
\end{solution}
\end{extra}

\begin{extra}\mc
The $M/M/c$ shorthand means that jobs arrive as a Poisson process, job service times are exponentially distributed, and there are $c$ servers.
\begin{solution}
True, the definition of a $M/M/c$ queue is stated as below.
$M/M/c$: A \recall{multi-server} queue with $c$ servers in which
 all servers have the same service capacity. Jobs arrive according to a
 Poisson process and have exponentially distributed service times.
\end{solution}
\end{extra}

\begin{extra}
 What is the meaning of $M/M/c/K$?
\begin{solution}
$M/M/c/K$: Inter-arrival times and process times are exponential,
 and the \recall{system capacity} is $K$ jobs. Thus, the queue can
 contain at most $K-c$ jobs. 

\end{solution}
\end{extra}


\begin{extra}
 What is the meaning of $M/M/c/c$?
\begin{solution}
 $M/M/c/c$: In this system the number of servers is the same as
 the system capacity, thus the queue length is always zero. This
 queueing system is useful to determine the number of beds
 in a hospital; the beds act as servers.
\end{solution}
\end{extra}

\begin{exercise}\clabel{ex:l-143}
 What is the meaning of $M(n)/M(n)/1$?
\begin{solution}
$M(n)/M(n)/1$: The inter-arrival times are exponential, just as
 the service times, but the rates of the arrival and service processes
 may depend on the queue length $n$. 
\end{solution}
\end{exercise}


\begin{exercise}\clabel{ex:l-144}
 What is the meaning of $M^X/M/1$?
\begin{solution}
  $M^X/M/1$: Customers arrive with exponentially distributed inter-arrival times.
  However, each customer brings in a number of jobs, known as a batch.
  The number of jobs in each batch is distributed as the random variable $X$.
  Thus, the arrival process of work is \recall{compound Poisson}.
\end{solution}
\end{exercise}

\begin{extra}
 What is the meaning of $M/G/1$?
\begin{solution}
$M/G/1$: The inter-arrival times are exponentially distributed,
 the service times can have any general distribution (with
 finite mean), and there is 1 server.
\end{solution}
\end{extra}


\begin{extra}
 What is the meaning of $M/G/\infty$?
\begin{solution}
 $M/G/\infty$: Exponential inter-arrival times, service times can
 have any distribution, and there is an unlimited supply of
 servers. This is also known as an \recall{ample server}. Observe
 that in this queueing process, jobs actually never have to wait in
 queue; upon arrival there is always a free server available.
\end{solution}
\end{extra}

\begin{extra}
 What is the meaning of $G/G/1$?
\begin{solution}
 $G/G/1$: Generally distributed inter-arrival and service times, 1 server.
\end{solution}
\end{extra}

\begin{extra}
 What is the meaning of $M/D/1-LIFO$?
\begin{solution}
 $M/D/1-LIFO$: Now, job service times are deterministic, and the service sequence is last-in-first-out (LIFO).
\end{solution}
\end{extra}

\begin{exercise}\clabel{ex:l-145}
 Is the $M/D/1$ queue a specific type of $M/G/c$ queue? 
\begin{solution}
 Yes, take $G=D$ and $c=1$. 
\end{solution}
\end{exercise}

You should also understand the differences between  different scheduling rules. The next exercise should help with this. 

\begin{exercise}\clabel{ex:l-146}
 What are some advantages and disadvantages of using the Shortest Processing Time First (SPTF) rule to serve jobs?
\begin{hint}
Look up the relevant
 definitions on Wikipedia or
 \citet{hall91:_queuein_method_servic_manuf}.
\end{hint}
\begin{solution}
 Advantage: SPTF minimizes the number of jobs in queue.
 Thus, if you want to keep the shop floor free of jobs, then this is certainly a good rule.
 Disadvantage: large jobs get near to terrible waiting times, and the variance of the waiting time increases.
 Thus, the $C_s^2$ is larger than under FIFO.
 Also, SPTF does not take due dates into account, thus giving a reliable due date quotation to a customer is hard (near to impossible).
\end{solution}
\end{exercise}

When a customer finds a large queue in front of it, s/he can use the normal distribution to estimate the distribution of the time s/he will spend in queue.  The next exercise shows how. 


\begin{exercise}\clabel{ex:l-147}
 Suppose for the $G/G/1$ that a job sees $n$ jobs in the system upon arrival.
 Use the central limit theorem to estimate the distribution of the waiting time in queue for this job.
\begin{hint}
 Let $W_{Q,n} = \sum_{k=1}^n S_k$.
 Since $\{S_k\}$ are assumed to be i.i.d.
 for the $G/G/1$ queue, $W_{Q,n}$ has mean $\mu_n = n \E S$ and $\sigma_n^2 = n\V S$.
\end{hint}
\begin{solution} Under conditions you can find on the internet,
 \begin{equation*}
 \frac{W_{Q,n} - \mu_n}{\sigma_n} \to \mathcal{N}(0,1), \quad\text{as } n\to \infty,
 \end{equation*}
 where $\mathcal{N}(0,1)$ is a normally distributed random variable
 with $\mu=0$ and $\sigma^2=1$. But then 
 \begin{align*}
 \frac{W_{Q,n} - \mu_n}{\sigma_n} &\approx \mathcal{N}(0,1) \iff\\
 W_{Q,n} - \mu_n &\approx \sigma_n \mathcal{N}(0,1) \iff\\
 W_{Q,n} - \mu_n &\approx \mathcal{N}(0,\sigma_n^2) \iff\\
 W_{Q,n} &\approx \mu_n + \mathcal{N}(0,\sigma_n^2) \iff\\
 W_{Q,n} &\approx \mathcal{N}(\mu_n,\sigma_n^2) = \mathcal{N}(n\E X, n \V S)
 \end{align*}
, where we used in the last equation the fact that the variance of the summation of i.i.d random variables is equal to the summation of the variances.
\end{solution}
\end{exercise}


\opt{solutionfiles}{
\Closesolutionfile{hint}
\Closesolutionfile{ans}
\subsection*{Hints}
\input{hint}
\subsection*{Solutions}
\input{ans}
}

%\clearpage

%%% Local Variables:
%%% mode: latex
%%% TeX-master: "../companion"
%%% End:
